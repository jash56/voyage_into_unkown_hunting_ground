{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXZXXq0h3kP8"
      },
      "source": [
        "# Load Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKwunz6qBc4X"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL-xuTxYG0g8"
      },
      "source": [
        "# Mount Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CWrbnnztduH",
        "outputId": "06b6118f-9288-45dd-b6f8-c6ad464d0d30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set device as GPU if available"
      ],
      "metadata": {
        "id": "rbNlQN_w0jfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "KnEJVFZA0gxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA_zNcNRG47x"
      },
      "source": [
        "#Project 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Training Function"
      ],
      "metadata": {
        "id": "aTHSUq_LRHrS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za0cb5NkRHrf"
      },
      "outputs": [],
      "source": [
        "def train_model(data_loader, model, loss_fn, optimizer, epochs):\n",
        "    train_dataset_size = len(data_loader.dataset)\n",
        "    num_batches = len(data_loader)\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        train_loss, correct = 0, 0\n",
        "        print(f'Start of epoch [{epoch+1}/{epochs}]')\n",
        "        for batch_number, data in enumerate(data_loader):\n",
        "            X, y = data\n",
        "            # Compute prediction and loss\n",
        "            probabilities = model(X)\n",
        "            loss = loss_fn(probabilities, y)\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Compute and display training loss and number of correct predictions at each epoch\n",
        "            prediction = torch.argmax(probabilities, axis=1)\n",
        "            train_loss += loss.item() \n",
        "            correct += (prediction == y).sum().item()\n",
        "\n",
        "            if batch_number % 100 == 0:\n",
        "                print(f'Batch [{batch_number+1}/{num_batches}] --> Accuracy: {(correct/(64*(batch_number+1))):.4f}')\n",
        "\n",
        "            # For every 3 batches of data trained on write data for tensorboard\n",
        "            if batch_number % 3 == 0:\n",
        "                train_writer.add_scalar('loss', (train_loss/(64*(batch_number+1))), (epoch * train_dataset_size) + (64*(batch_number + 1)))\n",
        "                train_writer.add_scalar('accuracy', (correct/(64*(batch_number+1))), (epoch * train_dataset_size) + (64*(batch_number + 1)))\n",
        "          \n",
        "        print(f'End of epoch [{epoch+1}/{epochs}], Loss: {train_loss/train_dataset_size:.4f}, Accuracy: {(correct/train_dataset_size):.4f}')\n",
        "    print(\"Done Training!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Testing Function"
      ],
      "metadata": {
        "id": "7wDbJrnEcuXD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBtMiJMzcuXK"
      },
      "outputs": [],
      "source": [
        "def test_model(data_loader, model, loss_fn):\n",
        "    test_dataset_size = len(test_loader.dataset)\n",
        "    num_batches = len(test_loader)\n",
        "    with torch.no_grad():\n",
        "        test_loss, correct = 0, 0\n",
        "        for batch_number, data in enumerate(test_loader):\n",
        "            X, y = data\n",
        "            # Compute prediction and loss\n",
        "            probabilities = model(X)\n",
        "            loss = loss_fn(probabilities, y)\n",
        "\n",
        "            # Compute and display testing loss and number of correct predictions \n",
        "            prediction = torch.argmax(probabilities, axis=1)\n",
        "            test_loss += loss.item() \n",
        "            correct += (prediction == y).sum().item()\n",
        "\n",
        "            if batch_number % 3 == 0:\n",
        "                print(f'Batch [{batch_number+1}/{num_batches}] --> Accuracy: {(correct/(64*(batch_number+1))):.4f}')\n",
        "                test_writer.add_scalar('accuracy', (correct/(64*(batch_number+1))), (64*(batch_number + 1)))\n",
        "          \n",
        "    print(f'Final Test Data Loss: {test_loss/test_dataset_size:.4f}, Accuracy: {(correct/test_dataset_size):.4f}')\n",
        "    print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Train/Test Datasets and Convert to Tensors"
      ],
      "metadata": {
        "id": "Ks4jM07963MF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMpC93GBNRb_"
      },
      "outputs": [],
      "source": [
        "class GridWorldDataset(Dataset):\n",
        "\n",
        "    def __init__(self, file, transform=torch.tensor):\n",
        "        data = joblib.load(file)\n",
        "        df = pd.DataFrame(data, columns=['agent_view','blocked_state','unblocked_state','hidden_state','sensed_count','neigbor_count', 'move'])\n",
        "        self.gridview_x = df[['agent_view','blocked_state','unblocked_state','hidden_state','sensed_count','neigbor_count']]\n",
        "        self.move_y = df['move']\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.move_y)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.gridview_x.iloc[index], self.move_y.iloc[index]\n",
        "        x, y = self.transform(x), self.transform(y)\n",
        "        return x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SL7ru1C0-Cyv"
      },
      "outputs": [],
      "source": [
        "#Train data loader\n",
        "train_data_path = '/content/drive/MyDrive/proj2_train_data_1'\n",
        "train_data = GridWorldDataset(file=train_data_path, transform=torch.tensor)\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "\n",
        "#Test data loader\n",
        "test_data_path = '/content/drive/MyDrive/proj2_train_data_1'\n",
        "test_data = GridWorldDataset(file=test_data_path, transform=torch.tensor)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Simple Neural Net"
      ],
      "metadata": {
        "id": "2uv1kvSl2l8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Neural Net Model Architecture"
      ],
      "metadata": {
        "id": "H77zKIR_8PlZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UR8W92z-C8L"
      },
      "outputs": [],
      "source": [
        "# Neural net architecture\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.l1 = nn.Linear(64*6, 64*3) \n",
        "        self.l2 = nn.Linear(64*3, 64) \n",
        "        self.l3 = nn.Linear(64, 16) \n",
        "        self.l4 = nn.Linear(16, 4)  \n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x.float())\n",
        "        x = self.l1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.l2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.l3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.l4(x)\n",
        "        logits = self.relu(x)\n",
        "        probabilities = self.softmax(logits)\n",
        "        return probabilities\n",
        "\n",
        "# Model of NN\n",
        "model = NeuralNet().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM4u-VLw-xmy"
      },
      "source": [
        "###Training Simple Neural Net Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQgRh3f0-1Er"
      },
      "outputs": [],
      "source": [
        "train_writer = SummaryWriter('runs/proj2/nn/train')\n",
        "train_model(train_loader, model, loss_fn = nn.CrossEntropyLoss(), optimizer = torch.optim.Adam(model.parameters(), lr=0.001), epochs = 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Model"
      ],
      "metadata": {
        "id": "0wo-Roo0w0ZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH='model/proj2/nn.pt'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "jvQRIVkLwzAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Model"
      ],
      "metadata": {
        "id": "SEaF4rYkxqIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNet()\n",
        "PATH='model/proj2/nn.pt' \n",
        "model.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GzcwchOxqIo",
        "outputId": "24a63d9e-7009-45ae-839b-4f3c8f8263a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBwNWHOj-7tc"
      },
      "source": [
        "###Testing Simple Neural Net Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fifnaWM4i_LI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39ee0fc3-c8dd-4025-de79-f1ee62443fa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch [1/234] --> Accuracy: 0.9844\n",
            "Batch [4/234] --> Accuracy: 0.9805\n",
            "Batch [7/234] --> Accuracy: 0.9710\n",
            "Batch [10/234] --> Accuracy: 0.9719\n",
            "Batch [13/234] --> Accuracy: 0.9700\n",
            "Batch [16/234] --> Accuracy: 0.9727\n",
            "Batch [19/234] --> Accuracy: 0.9753\n",
            "Batch [22/234] --> Accuracy: 0.9751\n",
            "Batch [25/234] --> Accuracy: 0.9756\n",
            "Batch [28/234] --> Accuracy: 0.9743\n",
            "Batch [31/234] --> Accuracy: 0.9753\n",
            "Batch [34/234] --> Accuracy: 0.9752\n",
            "Batch [37/234] --> Accuracy: 0.9751\n",
            "Batch [40/234] --> Accuracy: 0.9746\n",
            "Batch [43/234] --> Accuracy: 0.9760\n",
            "Batch [46/234] --> Accuracy: 0.9759\n",
            "Batch [49/234] --> Accuracy: 0.9761\n",
            "Batch [52/234] --> Accuracy: 0.9757\n",
            "Batch [55/234] --> Accuracy: 0.9756\n",
            "Batch [58/234] --> Accuracy: 0.9755\n",
            "Batch [61/234] --> Accuracy: 0.9759\n",
            "Batch [64/234] --> Accuracy: 0.9768\n",
            "Batch [67/234] --> Accuracy: 0.9764\n",
            "Batch [70/234] --> Accuracy: 0.9763\n",
            "Batch [73/234] --> Accuracy: 0.9758\n",
            "Batch [76/234] --> Accuracy: 0.9764\n",
            "Batch [79/234] --> Accuracy: 0.9767\n",
            "Batch [82/234] --> Accuracy: 0.9760\n",
            "Batch [85/234] --> Accuracy: 0.9754\n",
            "Batch [88/234] --> Accuracy: 0.9757\n",
            "Batch [91/234] --> Accuracy: 0.9751\n",
            "Batch [94/234] --> Accuracy: 0.9749\n",
            "Batch [97/234] --> Accuracy: 0.9747\n",
            "Batch [100/234] --> Accuracy: 0.9745\n",
            "Batch [103/234] --> Accuracy: 0.9744\n",
            "Batch [106/234] --> Accuracy: 0.9739\n",
            "Batch [109/234] --> Accuracy: 0.9733\n",
            "Batch [112/234] --> Accuracy: 0.9736\n",
            "Batch [115/234] --> Accuracy: 0.9739\n",
            "Batch [118/234] --> Accuracy: 0.9735\n",
            "Batch [121/234] --> Accuracy: 0.9737\n",
            "Batch [124/234] --> Accuracy: 0.9738\n",
            "Batch [127/234] --> Accuracy: 0.9738\n",
            "Batch [130/234] --> Accuracy: 0.9742\n",
            "Batch [133/234] --> Accuracy: 0.9742\n",
            "Batch [136/234] --> Accuracy: 0.9744\n",
            "Batch [139/234] --> Accuracy: 0.9740\n",
            "Batch [142/234] --> Accuracy: 0.9738\n",
            "Batch [145/234] --> Accuracy: 0.9738\n",
            "Batch [148/234] --> Accuracy: 0.9741\n",
            "Batch [151/234] --> Accuracy: 0.9737\n",
            "Batch [154/234] --> Accuracy: 0.9735\n",
            "Batch [157/234] --> Accuracy: 0.9734\n",
            "Batch [160/234] --> Accuracy: 0.9731\n",
            "Batch [163/234] --> Accuracy: 0.9734\n",
            "Batch [166/234] --> Accuracy: 0.9737\n",
            "Batch [169/234] --> Accuracy: 0.9737\n",
            "Batch [172/234] --> Accuracy: 0.9738\n",
            "Batch [175/234] --> Accuracy: 0.9737\n",
            "Batch [178/234] --> Accuracy: 0.9734\n",
            "Batch [181/234] --> Accuracy: 0.9734\n",
            "Batch [184/234] --> Accuracy: 0.9732\n",
            "Batch [187/234] --> Accuracy: 0.9733\n",
            "Batch [190/234] --> Accuracy: 0.9732\n",
            "Batch [193/234] --> Accuracy: 0.9734\n",
            "Batch [196/234] --> Accuracy: 0.9734\n",
            "Batch [199/234] --> Accuracy: 0.9735\n",
            "Batch [202/234] --> Accuracy: 0.9736\n",
            "Batch [205/234] --> Accuracy: 0.9739\n",
            "Batch [208/234] --> Accuracy: 0.9736\n",
            "Batch [211/234] --> Accuracy: 0.9739\n",
            "Batch [214/234] --> Accuracy: 0.9742\n",
            "Batch [217/234] --> Accuracy: 0.9742\n",
            "Batch [220/234] --> Accuracy: 0.9741\n",
            "Batch [223/234] --> Accuracy: 0.9741\n",
            "Batch [226/234] --> Accuracy: 0.9740\n",
            "Batch [229/234] --> Accuracy: 0.9741\n",
            "Batch [232/234] --> Accuracy: 0.9739\n",
            "Final Test Data Loss: 0.0121, Accuracy: 0.9739\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "test_writer = SummaryWriter('runs/proj2/nn/test')\n",
        "test_model(test_loader, model, loss_fn = nn.CrossEntropyLoss())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcsFsBRszVv8"
      },
      "source": [
        "###Tensorboard data analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5oB7_YLzVwC"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convulational Neural Net"
      ],
      "metadata": {
        "id": "TWrnqmDs9Mex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convulational Neural Net Model Architecture"
      ],
      "metadata": {
        "id": "jaUDYH3SfDZ_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRUqD5AcfDZ_"
      },
      "outputs": [],
      "source": [
        "# Convulational Neural net architecture\n",
        "class ConvulationalNeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvulationalNeuralNet, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.l1 = nn.Conv2d(6, 32, kernel_size=2, stride=1, padding=0) \n",
        "        self.l2 = nn.Conv2d(32, 64, kernel_size=2, stride=1, padding=0) \n",
        "        self.l3 = nn.Conv2d(64, 64, kernel_size=2, stride=1, padding=0)\n",
        "        self.l4 = nn.Conv2d(64, 32, kernel_size=2, stride=1, padding=0) \n",
        "        self.l5 = nn.Conv2d(32, 16, kernel_size=2, stride=1, padding=0) \n",
        "        self.l6 = nn.Linear(16*3*3, 4) \n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.float()\n",
        "        x = self.l1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.l2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.l3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.l4(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.l5(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.l6(x)\n",
        "        logits = self.relu(x)\n",
        "        probabilities = self.softmax(logits)\n",
        "        return probabilities\n",
        "\n",
        "# Model of CNN\n",
        "cnn_model = ConvulationalNeuralNet().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LgmOt3zfDaA"
      },
      "source": [
        "###Training Convulational Neural Net Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5O2TtPNhfDaA"
      },
      "outputs": [],
      "source": [
        "train_writer = SummaryWriter('runs/proj1/cnn/train')\n",
        "train_model(train_loader, cnn_model, loss_fn = nn.CrossEntropyLoss(), optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.0001), epochs = 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Model"
      ],
      "metadata": {
        "id": "MeKvZEl4yHdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH='cnn.pt'\n",
        "torch.save(cnn_model.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "QWEqv20wyHdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Model"
      ],
      "metadata": {
        "id": "TTK5bNc3yduu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = ConvulationalNeuralNet()\n",
        "PATH='cnn.pt' \n",
        "cnn_model.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl8IE2anyduv",
        "outputId": "d8166714-d0f6-4744-bc1d-944fa9b89c54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIDGsSxQfDaA"
      },
      "source": [
        "###Testing Convulational Neural Net Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbMDwh16fDaA"
      },
      "outputs": [],
      "source": [
        "test_writer = SummaryWriter('runs/proj2/cnn/test')\n",
        "test_model(test_loader, cnn_model, loss_fn = nn.CrossEntropyLoss())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQrrBjyVniVe"
      },
      "source": [
        "###Tensorboard data analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cDWuDd5niVr"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IGOBMGYHn6e"
      },
      "source": [
        "## 4-Neighbor Agent Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "a_yCucZv7RH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import heapq as hq\n",
        "import copy\n",
        "import random\n",
        "import math\n",
        "import csv\n",
        "import joblib\n",
        "import time\n",
        "\n",
        "class Cell:\n",
        "    def __init__(self, x, y, state=0, fval=math.inf, gval=math.inf, hval=0, parent=(-10, -10)):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.hval = hval\n",
        "        self.fval = fval\n",
        "        self.gval = gval\n",
        "        self.parent = parent\n",
        "        self.state = state\n",
        "\n",
        "def generate_gridworld(dim, probability=0.0):\n",
        "    '''\n",
        "    Generate the gridworld of size [dim, dim]\n",
        "    0 is unblocked 1 is blocked\n",
        "    Each cell is blocked with probability p and unblocked with probability 1-p\n",
        "    Takes the dimension (n) and value of prbability p as input \n",
        "    and returns a nxn gridworld\n",
        "    '''\n",
        "    # random.seed(100) #for reproducible results\n",
        "    gridworld =  np.random.choice([1, 0], size=(dim,dim), p=[probability, 1-probability]) \n",
        "    gridworld[0][0]=0\n",
        "    gridworld[dim-1][dim-1]=0\n",
        "    return gridworld\n",
        "\n",
        "def sensing(gridworld, cell):\n",
        "    action_offset = [\n",
        "        (1, 0),  # E\n",
        "        (0, -1),  # S\n",
        "        (-1, 0),  # W\n",
        "        (0, 1),  # N\n",
        "        (1, 1),  # NE\n",
        "        (1, -1),  # SE\n",
        "        (-1, -1),  # SW\n",
        "        (-1, 1),  # NW\n",
        "    ]\n",
        "    count_blocked = 0\n",
        "    cell_x,cell_y = cell\n",
        "    for n in action_offset:\n",
        "        x = cell_x + n[0]\n",
        "        y = cell_y + n[1]\n",
        "        if 0 <= x < len(gridworld) and 0 <= y < len(gridworld):\n",
        "            if(gridworld[x][y] == 1):\n",
        "                count_blocked += 1\n",
        "    return count_blocked\n",
        "\n",
        "\n",
        "def get_neighbors_8(dim, cell):\n",
        "    action_offset = [\n",
        "        (1, 0),  # E\n",
        "        (0, -1),  # S\n",
        "        (-1, 0),  # W\n",
        "        (0, 1),  # N\n",
        "        (1, 1),  # NE\n",
        "        (1, -1),  # SE\n",
        "        (-1, -1),  # SW\n",
        "        (-1, 1),  # NW\n",
        "    ]\n",
        "    neighbors = []\n",
        "    cell_x,cell_y = cell\n",
        "    for n in action_offset:\n",
        "        x = cell_x + n[0]\n",
        "        y = cell_y + n[1]\n",
        "        if 0 <= x < dim and 0 <= y < dim:\n",
        "            neighbors.append((x, y))\n",
        "    return neighbors, len(neighbors)\n",
        "\n",
        "\n",
        "def genrate_params_slice(dim,cell,agent_grid_view):\n",
        "\n",
        "    padded_data = np.full((dim+10,dim+10),-1)\n",
        "    for i in range(dim):\n",
        "        for j in range(dim):\n",
        "            padded_data[i+4][j+4] = agent_grid_view[i][j]\n",
        "    x,y = cell\n",
        "    slice = padded_data[x-3+4:x+5+4,y-3+4:y+5+4]\n",
        "    if(slice.shape[0]<8 or slice.shape[1]<8):\n",
        "        print('fucked',slice.shape)\n",
        "\n",
        "    return slice     \n",
        "    \n",
        "def get_nearby_cells(dim,cell,agent_grid_view,l=2):\n",
        "    agent_grid_view[cell[0]][cell[1]]=5\n",
        "    padded_data = np.full((dim+10,dim+10),-1)\n",
        "\n",
        "    for i in range(dim):\n",
        "        for j in range(dim):\n",
        "            padded_data[i+4][j+4] = agent_grid_view[i][j]\n",
        "    x,y = cell\n",
        "    slice = padded_data[x-3+4:x+5+4,y-3+4:y+5+4]\n",
        "    # print(agent_grid_view)\n",
        "    # print(slice)  \n",
        "    # print(slice.shape,'current_cell',cell)\n",
        "    if(slice.shape[0]<8 or slice.shape[1]<8):\n",
        "\n",
        "        print('fucked',slice.shape)\n",
        "\n",
        "    return slice     "
      ],
      "metadata": {
        "id": "BXqwIYDr7OLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Original AI Agent Implementation"
      ],
      "metadata": {
        "id": "Tl5Tt6lt7cbf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM_w2RAYHk1g"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import heapq as hq\n",
        "\n",
        "\n",
        "class PathFinder:\n",
        "    def __init__(self, gridworld, agent_grid_view, dim, start, target):\n",
        "        \"\"\"\n",
        "        Builder function\n",
        "        Takes Paramets: gridworld, agent_grid_view, belief_state, dim, start, target, agent\n",
        "        \"\"\"\n",
        "        self.gridworld = gridworld\n",
        "        self.dim = dim\n",
        "        self.agent_grid_view = agent_grid_view\n",
        "\n",
        "        # data set\n",
        "        self.agent_block_cells = np.full((dim,dim),0)\n",
        "        self.agent_unblocked_cells = np.full((dim,dim),0)\n",
        "        self.agent_hidden_cells = np.full((dim,dim),8)\n",
        "        self.agent_sensed_blocks = np.full((dim,dim),0)\n",
        "        self.agent_neighbor_count = np.full((dim,dim),0)\n",
        "\n",
        "\n",
        "        self.agent_infered_state = np.full((dim,dim),-2)\n",
        "\n",
        "        self.start = start\n",
        "        self.target = target\n",
        "        self.goal = (dim-1, dim-1)  # Initialize fixed goal\n",
        "        self.cells = {}  # Initialize Cells Hash\n",
        "        self.children_hash = {}  # Initiliaze Children Hash\n",
        "\n",
        "        self.blocks_encountered = 0  # keep track of blocks encountered\n",
        "        self.replans_count = 0  # Counter to keep track of no of replans\n",
        "        self.cells_processed=0\n",
        "        self.examination_cost = 0  # No of nodes actually examined\n",
        "        self.states=[]\n",
        "        self.states_cell = {}\n",
        "        # create cell objects\n",
        "        for i in range(0, dim):\n",
        "            for j in range(0, dim):\n",
        "                self.cells[(i, j)] = Cell(i, j)\n",
        "\n",
        "    def heuristic(self, x1, y1):\n",
        "        \"\"\"\n",
        "        Function used to calculate Manhattan Distance. \n",
        "        Takes row,col as input and returns the Manhattan Distance\n",
        "        \"\"\"\n",
        "        x2, y2 = self.goal\n",
        "        return abs(x1-x2) + abs(y1-y2)\n",
        "\n",
        "    def get_children(self, cell_x, cell_y):\n",
        "        \"\"\"\n",
        "        function used to get the next valid reachable cells from given cell\n",
        "        Takes row,col as input and returns the next possible children of given cell\n",
        "        \"\"\"\n",
        "        if self.children_hash.get((cell_x, cell_y)) != None:\n",
        "            return self.children_hash.get((cell_x, cell_y))\n",
        "        action_offset = [\n",
        "            (1, 0),  # Right\n",
        "            (0, -1),  # Down\n",
        "            (-1, 0),  # Left\n",
        "            (0, 1),  # Up\n",
        "        ]\n",
        "        children = []\n",
        "        for n in action_offset:\n",
        "            x = cell_x + n[0]\n",
        "            y = cell_y + n[1]\n",
        "            if 0 <= x < self.dim and 0 <= y < self.dim:\n",
        "                children.append((x, y))\n",
        "        self.children_hash[(cell_x, cell_y)] = children\n",
        "        return children\n",
        "\n",
        "    def astar(self, start_cell, goal_cell):\n",
        "        \"\"\"\n",
        "        funciton to implement A* algorithm and caluclate path.\n",
        "        Input start node and given goal node, returns path from start node to goal node and a boolean solvable to indicate if goal is reachable from the start\n",
        "        \"\"\"\n",
        "        solvable = True\n",
        "        fringe = []\n",
        "        path = []\n",
        "        goal = goal_cell\n",
        "        start_cell = self.cells.get(start_cell)\n",
        "        start_cell.fval = self.heuristic(start_cell.x, start_cell.y)\n",
        "        start_cell.gval = 0\n",
        "        start_cell.state = 1\n",
        "        start_cell.parent = None\n",
        "        hq.heappush(fringe, (start_cell.fval, (start_cell.x, start_cell.y)))\n",
        "        visited_list = {}\n",
        "        self.cells_processed =0\n",
        "        while len(fringe):\n",
        "            current_cell = hq.heappop(fringe)\n",
        "            self.cells_processed+=1\n",
        "            current_cell = current_cell[1]\n",
        "            if current_cell == goal:\n",
        "                path = []\n",
        "                current_cell = self.cells.get(\n",
        "                    (current_cell[0], current_cell[1]))\n",
        "                while current_cell != None:\n",
        "                    path.append((current_cell.x, current_cell.y))\n",
        "                    current_cell = self.cells.get(\n",
        "                        (current_cell.x, current_cell.y)).parent\n",
        "                return path[::-1], True\n",
        "            elif visited_list.get(current_cell) == None:\n",
        "                # add cell to closed list since we are exploring\n",
        "                visited_list[current_cell] = current_cell\n",
        "                children = self.children_hash.get(\n",
        "                    (current_cell[0], current_cell[1]), self.get_children(current_cell[0], current_cell[1]))\n",
        "                # iterate through them and add them to fringe if they are not in closed set\n",
        "                parent = self.cells.get((current_cell[0], current_cell[1]))\n",
        "                for child_x, child_y in children:\n",
        "                    if self.agent_grid_view[child_x][child_y] == 1 or visited_list.get((child_x, child_y)) != None:\n",
        "                        continue\n",
        "                    else:\n",
        "                        child = self.cells.get((child_x, child_y))\n",
        "                        child.parent = parent\n",
        "                        child.gval = self.cells.get(current_cell).gval+1\n",
        "                        child.hval = self.heuristic(child_x, child_y)\n",
        "                        child.fval = child.gval+child.hval\n",
        "                        # add to fringe lowest one of multiple entries comes out\n",
        "                        hq.heappush(fringe, (child.fval, (child_x, child_y)))\n",
        "        solvable = False\n",
        "        return path, solvable\n",
        "\n",
        "    def replan_path(self, cell):\n",
        "        \"\"\"\n",
        "        Function used to replan path, when encountered a block on traversing the path given by A*\n",
        "        \"\"\"\n",
        "        self.replans_count += 1  # counter to count number of restarts\n",
        "        self.blocks_encountered+=1\n",
        "        restart_cell = self.cells.get(cell)\n",
        "        restart_cell.parent = None\n",
        "        restart_cell.gval = 0\n",
        "        restart_cell.hval = self.heuristic(restart_cell.x, restart_cell.y)\n",
        "        restart_cell.fval = restart_cell.hval\n",
        "        return self.astar((restart_cell.x, restart_cell.y), self.goal)\n",
        "    \n",
        "\n",
        "    def run_inference(self,inference_path):\n",
        "     cell_knowledge =[[]]\n",
        "    # balancing equation nx = bx+ex+hx\n",
        "     for cell in inference_path:\n",
        "\n",
        "        # update cells bx and ex , hx\n",
        "        blocked = 0\n",
        "        empty = 0\n",
        "\n",
        "        neighbors, cell_nx = get_neighbors_8(self.dim, cell)\n",
        "\n",
        "        # for each neighbor cell it's updated state\n",
        "        for neighbor in neighbors:\n",
        "            neighbor_x,neighbor_y = neighbor\n",
        "            if self.agent_infered_state[neighbor_x][neighbor_y] == 1:\n",
        "                blocked += 1\n",
        "            elif self.agent_infered_state[neighbor_x][neighbor_y] == 0:\n",
        "                empty += 1\n",
        "        \n",
        "       \n",
        "        # update the knowledge base grids \n",
        "        self.agent_neighbor_count[cell[0]][cell[1]] = cell_nx\n",
        "        self.agent_block_cells[cell[0]][cell[1]] = blocked\n",
        "        self.agent_unblocked_cells[cell[0]][cell[1]] = empty\n",
        "        self.agent_hidden_cells[cell[0]][cell[1]] = cell_nx-blocked-empty\n",
        "\n",
        "\n",
        "        cx =  self.agent_sensed_blocks[cell[0]][cell[1]]\n",
        "\n",
        "        bx =  self.agent_block_cells[cell[0]][cell[1]]\n",
        "\n",
        "        ex =  self.agent_unblocked_cells[cell[0]][cell[1]]\n",
        "\n",
        "        hx =  self.agent_hidden_cells[cell[0]][cell[1]]\n",
        "\n",
        "        nx =  self.agent_neighbor_count[cell[0]][cell[1]]\n",
        "\n",
        "        # print('update knowledge ',cell.x,cell.y,cell.nx,cell.cx,cell.bx,cell.ex,cell.hx)\n",
        "\n",
        "        # cell hx=0 nothing more to infer from it,skip it\n",
        "        if(self.agent_hidden_cells[cell[0]][cell[1]] == 0):  # rule 3\n",
        "            continue\n",
        "        # hidden neighbors are blocked\n",
        "\n",
        "        elif((nx-cx) == ex):  # rule 2\n",
        "            for neighbor in neighbors:\n",
        "                neighbor_x,neighbor_y = neighbor\n",
        "                if (self.agent_infered_state[neighbor_x][neighbor_y] == -2):\n",
        "                    self.agent_grid_view[neighbor_x][neighbor_y] = 1\n",
        "                    self.agent_infered_state[neighbor_x][neighbor_y] = 1\n",
        "\n",
        "            self.agent_block_cells[cell[0]][cell[1]] += self.agent_hidden_cells[cell[0]][cell[1]]\n",
        "            self.agent_hidden_cells[cell[0]][cell[1]] = 0  # doing this as we make all the hidden cell inferences\n",
        "        # making hidden neighbors unblocked\n",
        "        elif(cx == bx):  # rule 1\n",
        "            for neighbor in neighbors:\n",
        "                if (self.agent_infered_state[neighbor_x][neighbor_y] == -2):\n",
        "                    self.agent_grid_view[neighbor_x][neighbor_y] = 0\n",
        "                    self.agent_infered_state[neighbor_x][neighbor_y] = 1\n",
        "\n",
        "            self.agent_unblocked_cells[cell[0]][cell[1]] += hx\n",
        "            self.agent_hidden_cells[cell[0]][cell[1]] = 0   # doing this as we make all the hidden cell inferences\n",
        "\n",
        "# end of agent3 infrence\n",
        "\n",
        "\n",
        "    def execute_agent(self, start):\n",
        "        \"\"\"\n",
        "        Function that executes agent 11\n",
        "        Takes input initial random start state\n",
        "        Return the final path and cost metrics\n",
        "        \"\"\"\n",
        "        # Initializing all values\n",
        "        # print(\"Executing Agent\", self.agent)\n",
        "        start_cell = start\n",
        "        self.cells.get(start_cell).parent = None\n",
        "        goal_found = False\n",
        "        complete_path = []\n",
        "\n",
        "        path, solvable = self.astar(start_cell, self.goal)\n",
        "\n",
        "        time_step =0\n",
        "\n",
        "        while solvable and goal_found !=True:\n",
        "            for i,cell in enumerate(path):\n",
        "                time_step+=1\n",
        "\n",
        "                # sense knowledge of blocked cells \n",
        "                self.agent_sensed_blocks[cell[0]][cell[1]]=sensing(copy.deepcopy(self.gridworld),cell)\n",
        "\n",
        "                 # check for goal state\n",
        "                if cell[0] == self.goal[0]  and cell[1] == self.goal[1]:\n",
        "                    complete_path.append(cell)\n",
        "                    goal_found = True\n",
        "                    break\n",
        "                else:\n",
        "                    next_cell =  path[i+1] if i+1<len(path) else None\n",
        "                    if next_cell!=None and  self.gridworld[next_cell[0]][next_cell[1]] == 1:\n",
        "                            # revert to parent and replan\n",
        "                            self.agent_grid_view[next_cell[0]][next_cell[1]] = 1\n",
        "                            self.agent_infered_state[cell[0]][cell[1]]=1\n",
        "                            inference_path = path[i:]\n",
        "                        # run the inference engine to update agent knowledge\n",
        "                            self.run_inference(inference_path)\n",
        "                            self.blocks_encountered+=1\n",
        "                            path,solvable = self.replan_path(cell)\n",
        "\n",
        "                            break\n",
        "                    else:\n",
        "                        complete_path.append(cell)\n",
        "                        self.agent_infered_state[cell[0]][cell[1]]=0\n",
        "                        inference_path = path[i:]\n",
        "                        # run the inference engine to update agent knowledge\n",
        "                        self.run_inference(inference_path)\n",
        "\n",
        "                        # run the check for blocks on the remaning path\n",
        "                        future_block = False\n",
        "\n",
        "                        for r_cell in inference_path:\n",
        "                            c_x,c_y = r_cell\n",
        "                            if(self.agent_grid_view[c_x][c_y]==1):\n",
        "                                path,solvable = self.replan_path(cell)\n",
        "                                break\n",
        "\n",
        "        if goal_found:\n",
        "            # self.write_to_file()\n",
        "            print('Hidden goal found')\n",
        "            # write states to dump file)\n",
        "            return 1,len(complete_path),complete_path, self.replans_count, self.cells_processed\n",
        "        else:\n",
        "            \n",
        "            print('target not reachable')\n",
        "            return 0,0,[],self.replans_count, self.cells_processed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Agent Implementation"
      ],
      "metadata": {
        "id": "jMpjFL2iLWBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inference function for ML agent"
      ],
      "metadata": {
        "id": "EQORxTYhEPU8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-qWBVPiJoKP"
      },
      "outputs": [],
      "source": [
        "def inference(grid, model):\n",
        "  grid = torch.tensor(grid)\n",
        "  grid = grid.float()\n",
        "  grid = grid.unsqueeze(0)\n",
        "  grid = nn.Flatten()(grid)\n",
        "  with torch.no_grad():\n",
        "    model.eval()       \n",
        "    probabilities = model(grid)\n",
        "    probabilities = probabilities[0].to(device).detach().numpy()\n",
        "  return probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ML agent class\n"
      ],
      "metadata": {
        "id": "lz0L8ZUuEz54"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZc9SfYWJ1pK"
      },
      "outputs": [],
      "source": [
        "class Mlfinder:\n",
        "    def __init__(self, gridworld, agent_grid_view, dim, start, goal, ml_model):\n",
        "        \"\"\"\n",
        "        Builder function\n",
        "        Takes Paramets: gridworld, agent_grid_view, belief_state, dim, start, target, agent\n",
        "        \"\"\"\n",
        "        self.model = ml_model\n",
        "        self.gridworld = gridworld\n",
        "        self.dim = dim\n",
        "        self.agent_grid_view = agent_grid_view\n",
        "        self.start = start\n",
        "        self.goal = goal\n",
        "        self.cells = {}  # Initialize Cells Hash\n",
        "        self.children_hash = {}  # Initiliaze Children Hash\n",
        "        self.blocks_encountered = 0  # keep track of blocks encountered\n",
        "        self.replans_count = 0  # Counter to keep track of no of replans\n",
        "        self.cells_processed=0\n",
        "        self.examination_cost = 0  # No of nodes actually examined\n",
        "        # create cell objects\n",
        "        for i in range(0, dim):\n",
        "            for j in range(0, dim):\n",
        "                self.cells[(i, j)] = Cell(i, j)\n",
        "        # data set\n",
        "        self.agent_block_cells = np.full((dim,dim),0)\n",
        "        self.agent_unblocked_cells = np.full((dim,dim),0)\n",
        "        self.agent_hidden_cells = np.full((dim,dim),8)\n",
        "        self.agent_sensed_blocks = np.full((dim,dim),0)\n",
        "        self.agent_neighbor_count = np.full((dim,dim),0)\n",
        "\n",
        "\n",
        "        self.agent_infered_state = np.full((dim,dim),-2)        \n",
        "   \n",
        "    def get_children(self, cell_x, cell_y):\n",
        "        \"\"\"\n",
        "        function used to get the next valid reachable cells from given cell\n",
        "        Takes row,col as input and returns the next possible children of given cell\n",
        "        \"\"\"\n",
        "        if self.children_hash.get((cell_x, cell_y)) != None:\n",
        "            return self.children_hash.get((cell_x, cell_y))\n",
        "        action_offset = [\n",
        "            (1, 0),  # Right\n",
        "            (0, -1),  # Down\n",
        "            (-1, 0),  # Left\n",
        "            (0, 1),  # Up\n",
        "        ]\n",
        "        children = []\n",
        "        for n in action_offset:\n",
        "            x = cell_x + n[0]\n",
        "            y = cell_y + n[1]\n",
        "            if 0 <= x < self.dim and 0 <= y < self.dim:\n",
        "                children.append((x, y))\n",
        "        self.children_hash[(cell_x, cell_y)] = children\n",
        "        return children            \n",
        "\n",
        "    def get_cell(self, cell_x, cell_y,dir):\n",
        "        action_offset = {\n",
        "           0: (1, 0),  # Right\n",
        "            1:(0, -1),  # Down\n",
        "            2:(-1, 0),  # Left\n",
        "            3: (0, 1),  # Up\n",
        "        }\n",
        "        n = action_offset.get(dir)\n",
        "        x = cell_x + n[0]\n",
        "        y = cell_y + n[1]\n",
        "        if 0 <= x < self.dim and 0 <= y < self.dim:\n",
        "          if(self.gridworld[x][y]==1):\n",
        "            return None\n",
        "          return (x,y)\n",
        "        else:\n",
        "          return None  \n",
        "   \n",
        "    \n",
        "  \n",
        "    def run_kb_update(self,cell):\n",
        "    # balancing equation nx = bx+ex+hx\n",
        "    \n",
        "        # update cells bx and ex , hx\n",
        "        blocked = 0\n",
        "        empty = 0\n",
        "\n",
        "        neighbors, cell_nx = get_neighbors_8(self.dim, cell)\n",
        "\n",
        "        # for each neighbor cell it's updated state\n",
        "        for neighbor in neighbors:\n",
        "            neighbor_x,neighbor_y = neighbor\n",
        "            if self.agent_infered_state[neighbor_x][neighbor_y] == 1:\n",
        "                blocked += 1\n",
        "            elif self.agent_infered_state[neighbor_x][neighbor_y] == 0:\n",
        "                empty += 1\n",
        "        \n",
        "       \n",
        "        # update the knowledge base grids \n",
        "        self.agent_neighbor_count[cell[0]][cell[1]] = cell_nx\n",
        "        self.agent_block_cells[cell[0]][cell[1]] = blocked\n",
        "        self.agent_unblocked_cells[cell[0]][cell[1]] = empty\n",
        "        self.agent_hidden_cells[cell[0]][cell[1]] = cell_nx-blocked-empty\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def get_agent_state(self,current_cell):\n",
        "\n",
        "        # agent view slice\n",
        "        copy_view = copy.deepcopy(self.agent_grid_view)\n",
        "        sliced_agent_view_state = get_nearby_cells(self.dim,current_cell,copy_view,2)\n",
        "\n",
        "        # agent blocked slice =  bx\n",
        "        blocked_copy = copy.deepcopy(self.agent_block_cells)\n",
        "        sliced_agent_blocked_state = genrate_params_slice(self.dim,current_cell,blocked_copy)\n",
        "\n",
        "        # agent empty slice = ex\n",
        "        unblocked_copy = copy.deepcopy(self.agent_unblocked_cells)\n",
        "        sliced_agent_unblocked_state = genrate_params_slice(self.dim,current_cell,unblocked_copy)\n",
        "\n",
        "\n",
        "        # agent sensed slice = hx\n",
        "        hidden_copy = copy.deepcopy(self.agent_hidden_cells)\n",
        "        sliced_agent_hidden_state = genrate_params_slice(self.dim,current_cell,hidden_copy)\n",
        "\n",
        "        # agent sensed slice = cx\n",
        "        sensed_copy = copy.deepcopy(self.agent_sensed_blocks)\n",
        "        sliced_agent_sensed_state = genrate_params_slice(self.dim,current_cell,sensed_copy)\n",
        "\n",
        "        # agent sensed slice = nx\n",
        "        neighbor_copy = copy.deepcopy(self.agent_neighbor_count)\n",
        "        sliced_agent_neighbor_state = genrate_params_slice(self.dim,current_cell,neighbor_copy)\n",
        "\n",
        "        final_arr  = np.array([sliced_agent_view_state,sliced_agent_blocked_state,sliced_agent_unblocked_state,sliced_agent_hidden_state,sliced_agent_sensed_state,sliced_agent_neighbor_state])\n",
        "\n",
        "        return final_arr\n",
        "\n",
        "\n",
        "    \n",
        "    def get_next_cell(self,current_cell):\n",
        "      copy_agent_view = copy.deepcopy(self.agent_grid_view)\n",
        "      local_grid = self.get_agent_state(current_cell)\n",
        "      directions = inference(local_grid, self.model)\n",
        "      return directions\n",
        "    \n",
        "    def contious_cells(self,direction,cell):\n",
        "          cell_x,cell_y =cell\n",
        "          action_offset = {\n",
        "            0: (1, 0),  # Right\n",
        "            1: (0, -1),  # Down\n",
        "            2: (-1, 0),  # Left\n",
        "            3: (0, 1),  # Up\n",
        "                           }\n",
        "          n = action_offset.get(direction)\n",
        "          prediction = []\n",
        "          for i in range(5):\n",
        "               x = cell_x + n[0]*i\n",
        "               y = cell_y + n[1]*i\n",
        "               if 0 <= x < self.dim and 0 <= y < self.dim:\n",
        "                    prediction.append((x,y))\n",
        "          return prediction \n",
        "\n",
        "    def loop_cell(self,current_cell):\n",
        "      state = True\n",
        "      directions = self.get_next_cell(current_cell)\n",
        "      cell = None\n",
        "      no_direction = 0\n",
        "      while no_direction < 4 and cell == None:\n",
        "            no_direction += 1\n",
        "            direction = np.argmax(directions)\n",
        "            directions[direction] = -1\n",
        "            cell = self.get_cell(current_cell[0],current_cell[1],direction)\n",
        "      return self.contious_cells(direction,cell)if cell!=None else []    \n",
        "\n",
        "    def execute_agent(self, start):\n",
        "        \"\"\"\n",
        "        Function that executes agent 11\n",
        "        Takes input initial random start state\n",
        "        Return the final path and cost metrics\n",
        "        \"\"\"\n",
        "        # Initializing all values\n",
        "        # print(\"Executing Agent\", self.agent)\n",
        "        start_cell = start\n",
        "        self.cells.get(start_cell).parent = None\n",
        "        goal_found = False\n",
        "\n",
        "\n",
        "        time_step =0\n",
        "        complete_path = [start]\n",
        "        # Find path from random start state to random goal state \n",
        "        path = self.loop_cell(start)\n",
        "\n",
        "        while goal_found !=True and len(path)>0 and time_step<1000:\n",
        "            print('planned path',path)\n",
        "            for i,cell in enumerate(path):\n",
        "                time_step+=1\n",
        "                \n",
        "                if self.gridworld[cell[0]][cell[1]]==0:\n",
        "                      # sense knowledge of blocked cells \n",
        "                     self.agent_sensed_blocks[cell[0]][cell[1]]=sensing(copy.deepcopy(self.gridworld),cell)\n",
        "                     self.agent_infered_state[cell[0]][cell[1]]=0\n",
        "                     self.run_kb_update(cell)\n",
        "\n",
        "                 # check for goal state\n",
        "                if cell[0] == self.goal[0]  and cell[1] == self.goal[1]:\n",
        "                    complete_path.append(cell)\n",
        "                    goal_found = True\n",
        "                    break\n",
        "                else:\n",
        "                    \n",
        "                     if self.gridworld[cell[0]][cell[1]] == 1:\n",
        "                            # revert to parent and replan\n",
        "                            self.agent_grid_view[cell[0]][cell[1]] = 1\n",
        "                            self.agent_infered_state[cell[0]][cell[1]]=1 \n",
        "                            self.blocks_encountered+=1\n",
        "                            prev = complete_path.pop()\n",
        "                            self.run_kb_update(prev)\n",
        "                            path= self.loop_cell(prev)\n",
        "                            break\n",
        "                     else:                                       \n",
        "                        complete_path.append(cell)\n",
        "                        path=self.loop_cell(cell) \n",
        "                                      \n",
        "        if goal_found:\n",
        "            print('goal found by ML')\n",
        "            return 1,len(complete_path),complete_path, self.replans_count, self.cells_processed\n",
        "        else:\n",
        "            print('ML target not reachable')\n",
        "            return 0,0,[],self.replans_count, self.cells_processed"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execute both agents"
      ],
      "metadata": {
        "id": "BAV4BhenFFYX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xU7hYPoHQjQ"
      },
      "outputs": [],
      "source": [
        "from time import process_time\n",
        "\n",
        "def test_ml_agent(number_of_mazes):\n",
        "  dim = 20\n",
        "  start =(0,0)\n",
        "  goal =(dim-1,dim-1)\n",
        "\n",
        "  '''[[agent_solved, agent_unsolved],\n",
        "    [ml_agent_solved, ml_agent_unsolved]]'''\n",
        "  confusion_matrix = np.array([[0, 0], \n",
        "                        [0, 0]])\n",
        "  total_path_length = 0\n",
        "  total_run_time = 0\n",
        "  total_ml_path_length = 0\n",
        "  total_ml_run_time = 0\n",
        "  for i in range(number_of_mazes):\n",
        "    print(i,'sample------------------')\n",
        "    gridworld= generate_gridworld(dim, 0.3)\n",
        "\n",
        "    # start = process_time()\n",
        "    goal_found_agent,path_length,_, _, _ = PathFinder(gridworld, np.zeros((dim, dim)), dim, start, goal).execute_agent(start)\n",
        "    # runtime = process_time() - start\n",
        "\n",
        "    ml_model = NeuralNet()\n",
        "\n",
        "    PATH='/content/model/proj2/nn.pt' \n",
        "    ml_model.load_state_dict(torch.load(PATH))\n",
        "    # start_ml = process_time()\n",
        "    goal_found_ml, ml_path_length,_, _, _ = Mlfinder(gridworld, np.zeros((dim, dim)), dim, start, goal, ml_model).execute_agent(start)\n",
        "    # goal_found_ml, ml_path_length,_, _, _ = PathFinder(gridworld, np.zeros((dim, dim)), dim, start, goal).execute_agent(start)\n",
        "    # ml_runtime = process_time() - start_ml\n",
        "    \n",
        "    total_path_length += path_length\n",
        "    total_ml_path_length += ml_path_length\n",
        "    # total_run_time += runtime\n",
        "    # total_ml_run_time += ml_runtime\n",
        "    if goal_found_agent and goal_found_ml:\n",
        "      confusion_matrix[0][0] += 1\n",
        "    elif not goal_found_agent and not goal_found_ml:\n",
        "      confusion_matrix[1][1] += 1\n",
        "    elif not goal_found_agent and goal_found_ml:\n",
        "      confusion_matrix[1][0] += 1\n",
        "    elif goal_found_agent and not goal_found_ml:\n",
        "      confusion_matrix[0][1] += 1\n",
        "    else:\n",
        "      print(\"NOOB\")\n",
        "    print(i,'sample------------------')\n",
        "  accuracy = (confusion_matrix[0][0] + confusion_matrix[1][1]) / confusion_matrix.sum()\n",
        "  recall = confusion_matrix[0][0]/(confusion_matrix[0][0] + confusion_matrix[0][1])\n",
        "  precision = confusion_matrix[0][0]/(confusion_matrix[0][0] + confusion_matrix[1][0])\n",
        "\n",
        "  return confusion_matrix, accuracy, precision, recall, total_path_length/number_of_mazes, total_ml_path_length/number_of_mazes\n",
        "#traj len, planning time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def write_to_file(states, file_name):\n",
        "       try:\n",
        "          print('number of states apend',len(states))\n",
        "          joblib.dump(states, file_name, compress=3)\n",
        "       except OverflowError:  \n",
        "            print (\"OverFlow Exception Raised.\")"
      ],
      "metadata": {
        "id": "XcMYCRF5sYex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_tests = 1 #30\n",
        "sum_confusion_matrix = np.array([[0, 0], \n",
        "                            [0, 0]])\n",
        "sum_accuracy, sum_precision, sum_recall, sum_path_length, sum_ml_path_length = 0, 0, 0, 0, 0\n",
        "graph_data = []\n",
        "for i in range(number_of_tests):\n",
        "  confusion_matrix, accuracy, precision, recall, path_length, ml_path_length = test_ml_agent(number_of_mazes=10) # 100\n",
        "  graph_data.append([i, confusion_matrix, accuracy, precision, recall, path_length, ml_path_length])\n",
        "  sum_confusion_matrix += confusion_matrix\n",
        "  sum_accuracy += accuracy\n",
        "  sum_precision += precision\n",
        "  sum_recall += recall\n",
        "  sum_path_length += path_length\n",
        "  sum_ml_path_length += ml_path_length\n",
        "\n",
        "file_name = 'proj2_nn_data'\n",
        "write_to_file(graph_data, file_name)\n",
        "\n",
        "# avg_confusion_matrix = sum_confusion_matrix / number_of_tests\n",
        "# avg_accuracy = sum_accuracy / number_of_tests\n",
        "# avg_precision = sum_precision / number_of_tests\n",
        "# avg_recall = sum_recall / number_of_tests\n",
        "# avg_path_length = sum_path_length / number_of_tests\n",
        "# avg_ml_path_length = sum_ml_path_length / number_of_tests\n",
        "# print('avg')\n",
        "# print(avg_confusion_matrix, avg_accuracy, avg_precision, avg_recall)"
      ],
      "metadata": {
        "id": "jwu-AGMfFNfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = joblib.load('proj1_cnn_data')\n",
        "print(data)"
      ],
      "metadata": {
        "id": "stILqJP-tisc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jXZXXq0h3kP8",
        "iL-xuTxYG0g8",
        "rbNlQN_w0jfj",
        "aTHSUq_LRHrS",
        "7wDbJrnEcuXD",
        "iBwNWHOj-7tc",
        "jMpjFL2iLWBR"
      ],
      "name": "AI_Prjoect_4-Part2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}