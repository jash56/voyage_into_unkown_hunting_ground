{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXZXXq0h3kP8"
      },
      "source": [
        "# Load Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKwunz6qBc4X"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL-xuTxYG0g8"
      },
      "source": [
        "# Mount Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CWrbnnztduH",
        "outputId": "99ce0495-38d4-4254-d43a-e512931ea7c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set device as GPU if available"
      ],
      "metadata": {
        "id": "rbNlQN_w0jfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "KnEJVFZA0gxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA_zNcNRG47x"
      },
      "source": [
        "#Project 1 (4-Neighbor Agent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Training Function"
      ],
      "metadata": {
        "id": "aTHSUq_LRHrS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za0cb5NkRHrf"
      },
      "outputs": [],
      "source": [
        "def train_model(data_loader, model, loss_fn, optimizer, epochs):\n",
        "    train_dataset_size = len(data_loader.dataset)\n",
        "    num_batches = len(data_loader)\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        train_loss, correct = 0, 0\n",
        "        print(f'Start of epoch [{epoch+1}/{epochs}]')\n",
        "        for batch_number, data in enumerate(data_loader):\n",
        "            X, y = data\n",
        "            # Compute prediction and loss\n",
        "            probabilities = model(X)\n",
        "            loss = loss_fn(probabilities, y)\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Compute and display training loss and number of correct predictions at each epoch\n",
        "            prediction = torch.argmax(probabilities, axis=1)\n",
        "            train_loss += loss.item() \n",
        "            correct += (prediction == y).sum().item()\n",
        "\n",
        "            if batch_number % 100 == 0:\n",
        "                print(f'Batch [{batch_number+1}/{num_batches}] --> Accuracy: {(correct/(64*(batch_number+1))):.4f}')\n",
        "\n",
        "            # For every 3 batches of data trained on write data for tensorboard\n",
        "            if batch_number % 3 == 0:\n",
        "                train_writer.add_scalar('loss', (train_loss/(64*(batch_number+1))), (epoch * train_dataset_size) + (64*(batch_number + 1)))\n",
        "                train_writer.add_scalar('accuracy', (correct/(64*(batch_number+1))), (epoch * train_dataset_size) + (64*(batch_number + 1)))\n",
        "          \n",
        "        print(f'End of epoch [{epoch+1}/{epochs}], Loss: {train_loss/train_dataset_size:.4f}, Accuracy: {(correct/train_dataset_size):.4f}')\n",
        "    print(\"Done Training!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Testing Function"
      ],
      "metadata": {
        "id": "7wDbJrnEcuXD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBtMiJMzcuXK"
      },
      "outputs": [],
      "source": [
        "def test_model(data_loader, model, loss_fn):\n",
        "    test_dataset_size = len(test_loader.dataset)\n",
        "    num_batches = len(test_loader)\n",
        "    with torch.no_grad():\n",
        "        test_loss, correct = 0, 0\n",
        "        for batch_number, data in enumerate(test_loader):\n",
        "            X, y = data\n",
        "            # Compute prediction and loss\n",
        "            probabilities = model(X)\n",
        "            loss = loss_fn(probabilities, y)\n",
        "\n",
        "            # Compute and display testing loss and number of correct predictions \n",
        "            prediction = torch.argmax(probabilities, axis=1)\n",
        "            test_loss += loss.item() \n",
        "            correct += (prediction == y).sum().item()\n",
        "\n",
        "            if batch_number % 3 == 0:\n",
        "                print(f'Batch [{batch_number+1}/{num_batches}] --> Accuracy: {(correct/(64*(batch_number+1))):.4f}')\n",
        "                test_writer.add_scalar('accuracy', (correct/(64*(batch_number+1))), (64*(batch_number + 1)))\n",
        "          \n",
        "    print(f'Final Test Data Loss: {test_loss/test_dataset_size:.4f}, Accuracy: {(correct/test_dataset_size):.4f}')\n",
        "    print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Train/Test Datasets and Convert to Tensors"
      ],
      "metadata": {
        "id": "Ks4jM07963MF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMpC93GBNRb_"
      },
      "outputs": [],
      "source": [
        "class GridWorldDataset(Dataset):\n",
        "\n",
        "    def __init__(self, file, transform=torch.tensor):\n",
        "        data = joblib.load(file)\n",
        "        df = pd.DataFrame(data, columns=['marked_agent_grid', 'move'])\n",
        "        self.gridview_x = df['marked_agent_grid']\n",
        "        self.move_y = df['move']\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.move_y)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.gridview_x.iloc[index], self.move_y.iloc[index]\n",
        "        x, y = self.transform(x), self.transform(y)\n",
        "        return x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SL7ru1C0-Cyv"
      },
      "outputs": [],
      "source": [
        "#Train data loader\n",
        "train_data_path = '/content/drive/MyDrive/train_data'\n",
        "train_data = GridWorldDataset(file=train_data_path, transform=torch.tensor)\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "\n",
        "#Test data loader\n",
        "test_data_path = '/content/drive/MyDrive/test_data'\n",
        "test_data = GridWorldDataset(file=test_data_path, transform=torch.tensor)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Simple Neural Net"
      ],
      "metadata": {
        "id": "2uv1kvSl2l8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Neural Net Model Architecture"
      ],
      "metadata": {
        "id": "H77zKIR_8PlZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UR8W92z-C8L"
      },
      "outputs": [],
      "source": [
        "# Neural net architecture\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.l1 = nn.Linear(64, 32) \n",
        "        self.l2 = nn.Linear(32, 16) \n",
        "        self.l3 = nn.Linear(16, 16) \n",
        "        self.l4 = nn.Linear(16, 4)  \n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x.float())\n",
        "        x = self.l1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.l2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.l3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.l4(x)\n",
        "        logits = self.relu(x)\n",
        "        probabilities = self.softmax(logits)\n",
        "        return probabilities\n",
        "\n",
        "# Model of NN\n",
        "model = NeuralNet().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM4u-VLw-xmy"
      },
      "source": [
        "###Training Simple Neural Net Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQgRh3f0-1Er"
      },
      "outputs": [],
      "source": [
        "train_writer = SummaryWriter('runs/proj1/nn/train')\n",
        "train_model(train_loader, model, loss_fn = nn.CrossEntropyLoss(), optimizer = torch.optim.Adam(model.parameters(), lr=0.0001), epochs = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Model"
      ],
      "metadata": {
        "id": "0wo-Roo0w0ZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH='model/proj1/nn.pt'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "jvQRIVkLwzAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Model"
      ],
      "metadata": {
        "id": "SEaF4rYkxqIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNet()\n",
        "PATH='model/proj1/nn.pt' \n",
        "model.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GzcwchOxqIo",
        "outputId": "17fdd59f-2d92-418c-e5d9-f7b6366a2b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBwNWHOj-7tc"
      },
      "source": [
        "###Testing Simple Neural Net Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fifnaWM4i_LI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bddaa17a-2a47-45ad-f6be-5363a6ef4dca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch [1/316] --> Accuracy: 0.9219\n",
            "Batch [4/316] --> Accuracy: 0.9336\n",
            "Batch [7/316] --> Accuracy: 0.9129\n",
            "Batch [10/316] --> Accuracy: 0.9156\n",
            "Batch [13/316] --> Accuracy: 0.9171\n",
            "Batch [16/316] --> Accuracy: 0.9111\n",
            "Batch [19/316] --> Accuracy: 0.9104\n",
            "Batch [22/316] --> Accuracy: 0.9112\n",
            "Batch [25/316] --> Accuracy: 0.9137\n",
            "Batch [28/316] --> Accuracy: 0.9096\n",
            "Batch [31/316] --> Accuracy: 0.9093\n",
            "Batch [34/316] --> Accuracy: 0.9104\n",
            "Batch [37/316] --> Accuracy: 0.9092\n",
            "Batch [40/316] --> Accuracy: 0.9109\n",
            "Batch [43/316] --> Accuracy: 0.9117\n",
            "Batch [46/316] --> Accuracy: 0.9096\n",
            "Batch [49/316] --> Accuracy: 0.9107\n",
            "Batch [52/316] --> Accuracy: 0.9105\n",
            "Batch [55/316] --> Accuracy: 0.9105\n",
            "Batch [58/316] --> Accuracy: 0.9095\n",
            "Batch [61/316] --> Accuracy: 0.9096\n",
            "Batch [64/316] --> Accuracy: 0.9092\n",
            "Batch [67/316] --> Accuracy: 0.9074\n",
            "Batch [70/316] --> Accuracy: 0.9071\n",
            "Batch [73/316] --> Accuracy: 0.9077\n",
            "Batch [76/316] --> Accuracy: 0.9083\n",
            "Batch [79/316] --> Accuracy: 0.9086\n",
            "Batch [82/316] --> Accuracy: 0.9076\n",
            "Batch [85/316] --> Accuracy: 0.9070\n",
            "Batch [88/316] --> Accuracy: 0.9061\n",
            "Batch [91/316] --> Accuracy: 0.9057\n",
            "Batch [94/316] --> Accuracy: 0.9061\n",
            "Batch [97/316] --> Accuracy: 0.9058\n",
            "Batch [100/316] --> Accuracy: 0.9067\n",
            "Batch [103/316] --> Accuracy: 0.9066\n",
            "Batch [106/316] --> Accuracy: 0.9058\n",
            "Batch [109/316] --> Accuracy: 0.9057\n",
            "Batch [112/316] --> Accuracy: 0.9058\n",
            "Batch [115/316] --> Accuracy: 0.9058\n",
            "Batch [118/316] --> Accuracy: 0.9055\n",
            "Batch [121/316] --> Accuracy: 0.9059\n",
            "Batch [124/316] --> Accuracy: 0.9042\n",
            "Batch [127/316] --> Accuracy: 0.9040\n",
            "Batch [130/316] --> Accuracy: 0.9036\n",
            "Batch [133/316] --> Accuracy: 0.9041\n",
            "Batch [136/316] --> Accuracy: 0.9046\n",
            "Batch [139/316] --> Accuracy: 0.9049\n",
            "Batch [142/316] --> Accuracy: 0.9045\n",
            "Batch [145/316] --> Accuracy: 0.9047\n",
            "Batch [148/316] --> Accuracy: 0.9041\n",
            "Batch [151/316] --> Accuracy: 0.9038\n",
            "Batch [154/316] --> Accuracy: 0.9040\n",
            "Batch [157/316] --> Accuracy: 0.9036\n",
            "Batch [160/316] --> Accuracy: 0.9038\n",
            "Batch [163/316] --> Accuracy: 0.9039\n",
            "Batch [166/316] --> Accuracy: 0.9036\n",
            "Batch [169/316] --> Accuracy: 0.9032\n",
            "Batch [172/316] --> Accuracy: 0.9031\n",
            "Batch [175/316] --> Accuracy: 0.9035\n",
            "Batch [178/316] --> Accuracy: 0.9037\n",
            "Batch [181/316] --> Accuracy: 0.9040\n",
            "Batch [184/316] --> Accuracy: 0.9038\n",
            "Batch [187/316] --> Accuracy: 0.9039\n",
            "Batch [190/316] --> Accuracy: 0.9041\n",
            "Batch [193/316] --> Accuracy: 0.9037\n",
            "Batch [196/316] --> Accuracy: 0.9035\n",
            "Batch [199/316] --> Accuracy: 0.9040\n",
            "Batch [202/316] --> Accuracy: 0.9042\n",
            "Batch [205/316] --> Accuracy: 0.9047\n",
            "Batch [208/316] --> Accuracy: 0.9047\n",
            "Batch [211/316] --> Accuracy: 0.9050\n",
            "Batch [214/316] --> Accuracy: 0.9052\n",
            "Batch [217/316] --> Accuracy: 0.9047\n",
            "Batch [220/316] --> Accuracy: 0.9052\n",
            "Batch [223/316] --> Accuracy: 0.9057\n",
            "Batch [226/316] --> Accuracy: 0.9060\n",
            "Batch [229/316] --> Accuracy: 0.9064\n",
            "Batch [232/316] --> Accuracy: 0.9062\n",
            "Batch [235/316] --> Accuracy: 0.9059\n",
            "Batch [238/316] --> Accuracy: 0.9059\n",
            "Batch [241/316] --> Accuracy: 0.9060\n",
            "Batch [244/316] --> Accuracy: 0.9057\n",
            "Batch [247/316] --> Accuracy: 0.9059\n",
            "Batch [250/316] --> Accuracy: 0.9058\n",
            "Batch [253/316] --> Accuracy: 0.9057\n",
            "Batch [256/316] --> Accuracy: 0.9056\n",
            "Batch [259/316] --> Accuracy: 0.9056\n",
            "Batch [262/316] --> Accuracy: 0.9057\n",
            "Batch [265/316] --> Accuracy: 0.9057\n",
            "Batch [268/316] --> Accuracy: 0.9056\n",
            "Batch [271/316] --> Accuracy: 0.9059\n",
            "Batch [274/316] --> Accuracy: 0.9061\n",
            "Batch [277/316] --> Accuracy: 0.9062\n",
            "Batch [280/316] --> Accuracy: 0.9065\n",
            "Batch [283/316] --> Accuracy: 0.9066\n",
            "Batch [286/316] --> Accuracy: 0.9067\n",
            "Batch [289/316] --> Accuracy: 0.9067\n",
            "Batch [292/316] --> Accuracy: 0.9064\n",
            "Batch [295/316] --> Accuracy: 0.9063\n",
            "Batch [298/316] --> Accuracy: 0.9059\n",
            "Batch [301/316] --> Accuracy: 0.9059\n",
            "Batch [304/316] --> Accuracy: 0.9058\n",
            "Batch [307/316] --> Accuracy: 0.9055\n",
            "Batch [310/316] --> Accuracy: 0.9058\n",
            "Batch [313/316] --> Accuracy: 0.9059\n",
            "Batch [316/316] --> Accuracy: 0.9053\n",
            "Final Test Data Loss: 0.0127, Accuracy: 0.9058\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "test_writer = SummaryWriter('runs/proj1/nn/test')\n",
        "test_model(test_loader, model, loss_fn = nn.CrossEntropyLoss())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcsFsBRszVv8"
      },
      "source": [
        "###Tensorboard data analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5oB7_YLzVwC"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Convulational Neural Net"
      ],
      "metadata": {
        "id": "TWrnqmDs9Mex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convulational Neural Net Model Architecture"
      ],
      "metadata": {
        "id": "jaUDYH3SfDZ_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRUqD5AcfDZ_"
      },
      "outputs": [],
      "source": [
        "# Convulational Neural net architecture\n",
        "class ConvulationalNeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvulationalNeuralNet, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.l1 = nn.Conv2d(1, 32, kernel_size=2, stride=1, padding=0) \n",
        "        self.l2 = nn.Conv2d(32, 64, kernel_size=2, stride=1, padding=0) \n",
        "        self.l3 = nn.Conv2d(64, 64, kernel_size=2, stride=1, padding=0)\n",
        "        self.l4 = nn.Conv2d(64, 32, kernel_size=2, stride=1, padding=0) \n",
        "        self.l5 = nn.Conv2d(32, 16, kernel_size=2, stride=1, padding=0) \n",
        "        self.l6 = nn.Linear(144, 4) \n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.unsqueeze(x.float(), 1)\n",
        "        x = self.l1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.l2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.l3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.l4(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.l5(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.l6(x)\n",
        "        logits = self.relu(x)\n",
        "        probabilities = self.softmax(logits)\n",
        "        return probabilities\n",
        "\n",
        "# Model of CNN\n",
        "cnn_model = ConvulationalNeuralNet().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LgmOt3zfDaA"
      },
      "source": [
        "###Training Convulational Neural Net Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5O2TtPNhfDaA"
      },
      "outputs": [],
      "source": [
        "train_writer = SummaryWriter('runs/proj1/cnn/train')\n",
        "train_model(train_loader, cnn_model, loss_fn = nn.CrossEntropyLoss(), optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001), epochs = 50)\n",
        "train_model(train_loader, cnn_model, loss_fn = nn.CrossEntropyLoss(), optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.0001), epochs = 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Model"
      ],
      "metadata": {
        "id": "MeKvZEl4yHdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH='model/proj1/cnn.pt'\n",
        "torch.save(cnn_model.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "QWEqv20wyHdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Model"
      ],
      "metadata": {
        "id": "TTK5bNc3yduu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = ConvulationalNeuralNet()\n",
        "PATH='model/proj1/cnn.pt' \n",
        "cnn_model.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl8IE2anyduv",
        "outputId": "46e93765-eefe-4959-b675-fab7ae607741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIDGsSxQfDaA"
      },
      "source": [
        "###Testing Convulational Neural Net Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbMDwh16fDaA"
      },
      "outputs": [],
      "source": [
        "test_writer = SummaryWriter('runs/proj1/cnn/test')\n",
        "test_model(test_loader, cnn_model, loss_fn = nn.CrossEntropyLoss())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQrrBjyVniVe"
      },
      "source": [
        "###Tensorboard data analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cDWuDd5niVr"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IGOBMGYHn6e"
      },
      "source": [
        "## 4-Neighbor Agent Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "a_yCucZv7RH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import heapq as hq\n",
        "import copy\n",
        "import random\n",
        "import math\n",
        "import csv\n",
        "import joblib\n",
        "import time\n",
        "\n",
        "class Cell:\n",
        "    def __init__(self, x, y, state=0, fval=math.inf, gval=math.inf, hval=0, parent=(-10, -10)):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.hval = hval\n",
        "        self.fval = fval\n",
        "        self.gval = gval\n",
        "        self.parent = parent\n",
        "        self.state = state\n",
        "\n",
        "def generate_gridworld(dim, probability=0.0):\n",
        "    '''\n",
        "    Generate the gridworld of size [dim, dim]\n",
        "    0 is unblocked 1 is blocked\n",
        "    Each cell is blocked with probability p and unblocked with probability 1-p\n",
        "    Takes the dimension (n) and value of prbability p as input \n",
        "    and returns a nxn gridworld\n",
        "    '''\n",
        "    # random.seed(100) #for reproducible results\n",
        "    gridworld =  np.random.choice([1, 0], size=(dim,dim), p=[probability, 1-probability]) \n",
        "    gridworld[0][0]=0\n",
        "    gridworld[dim-1][dim-1]=0\n",
        "    return gridworld"
      ],
      "metadata": {
        "id": "BXqwIYDr7OLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Original AI Agent Implementation"
      ],
      "metadata": {
        "id": "Tl5Tt6lt7cbf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM_w2RAYHk1g"
      },
      "outputs": [],
      "source": [
        "class PathFinder:\n",
        "    def __init__(self, gridworld, agent_grid_view, dim, start, goal):\n",
        "        \"\"\"\n",
        "        Builder function\n",
        "        Takes Paramets: gridworld, agent_grid_view, belief_state, dim, start, target, agent\n",
        "        \"\"\"\n",
        "        self.gridworld = gridworld\n",
        "        self.dim = dim\n",
        "        self.agent_grid_view = agent_grid_view\n",
        "        self.start = start\n",
        "        self.goal = goal  \n",
        "        self.cells = {}  # Initialize Cells Hash\n",
        "        self.children_hash = {}  # Initiliaze Children Hash\n",
        "        self.blocks_encountered = 0  # keep track of blocks encountered\n",
        "        self.replans_count = 0  # Counter to keep track of no of replans\n",
        "        self.cells_processed=0\n",
        "        self.examination_cost = 0  # No of nodes actually examined\n",
        "        # create cell objects\n",
        "        for i in range(0, dim):\n",
        "            for j in range(0, dim):\n",
        "                self.cells[(i, j)] = Cell(i, j)\n",
        "\n",
        "    def heuristic(self, x1, y1):\n",
        "        \"\"\"\n",
        "        Function used to calculate Manhattan Distance. \n",
        "        Takes row,col as input and returns the Manhattan Distance\n",
        "        \"\"\"\n",
        "        x2, y2 = self.goal\n",
        "        return abs(x1-x2) + abs(y1-y2)\n",
        "\n",
        "    def get_children(self, cell_x, cell_y):\n",
        "        \"\"\"\n",
        "        function used to get the next valid reachable cells from given cell\n",
        "        Takes row,col as input and returns the next possible children of given cell\n",
        "        \"\"\"\n",
        "        if self.children_hash.get((cell_x, cell_y)) != None:\n",
        "            return self.children_hash.get((cell_x, cell_y))\n",
        "        action_offset = [\n",
        "            (1, 0),  # Right\n",
        "            (0, -1),  # Down\n",
        "            (-1, 0),  # Left\n",
        "            (0, 1),  # Up\n",
        "        ]\n",
        "        children = []\n",
        "        for n in action_offset:\n",
        "            x = cell_x + n[0]\n",
        "            y = cell_y + n[1]\n",
        "            if 0 <= x < self.dim and 0 <= y < self.dim:\n",
        "                children.append((x, y))\n",
        "        self.children_hash[(cell_x, cell_y)] = children\n",
        "        return children\n",
        "\n",
        "    def astar(self, start_cell, goal_cell):\n",
        "        \"\"\"\n",
        "        funciton to implement A* algorithm and caluclate path.\n",
        "        Input start node and given goal node, returns path from start node to goal node and a boolean solvable to indicate if goal is reachable from the start\n",
        "        \"\"\"\n",
        "        solvable = True\n",
        "        fringe = []\n",
        "        path = []\n",
        "        goal = goal_cell\n",
        "        start_cell = self.cells.get(start_cell)\n",
        "        start_cell.fval = self.heuristic(start_cell.x, start_cell.y)\n",
        "        start_cell.gval = 0\n",
        "        start_cell.parent = None\n",
        "        hq.heappush(fringe, (start_cell.fval, (start_cell.x, start_cell.y)))\n",
        "        visited_list = {}\n",
        "        self.cells_processed =0\n",
        "        while len(fringe):\n",
        "            current_cell = hq.heappop(fringe)\n",
        "            self.cells_processed+=1\n",
        "            current_cell = current_cell[1]\n",
        "            if current_cell == goal:\n",
        "                path = []\n",
        "                current_cell = self.cells.get(\n",
        "                    (current_cell[0], current_cell[1]))\n",
        "                while current_cell != None:\n",
        "                    path.append((current_cell.x, current_cell.y))\n",
        "                    current_cell = self.cells.get(\n",
        "                        (current_cell.x, current_cell.y)).parent\n",
        "                return path[::-1], True\n",
        "            elif visited_list.get(current_cell) == None:\n",
        "                # add cell to closed list since we are exploring\n",
        "                visited_list[current_cell] = current_cell\n",
        "                children = self.children_hash.get(\n",
        "                    (current_cell[0], current_cell[1]), self.get_children(current_cell[0], current_cell[1]))\n",
        "                # iterate through them and add them to fringe if they are not in closed set\n",
        "                parent = self.cells.get((current_cell[0], current_cell[1]))\n",
        "                for child_x, child_y in children:\n",
        "                    if self.agent_grid_view[child_x][child_y] == 1 or visited_list.get((child_x, child_y)) != None:\n",
        "                        continue\n",
        "                    else:\n",
        "                        child = self.cells.get((child_x, child_y))\n",
        "                        child.parent = parent\n",
        "                        child.gval = self.cells.get(current_cell).gval+1\n",
        "                        child.hval = self.heuristic(child_x, child_y)\n",
        "                        child.fval = child.gval+child.hval\n",
        "                        # add to fringe lowest one of multiple entries comes out\n",
        "                        hq.heappush(fringe, (child.fval, (child_x, child_y)))\n",
        "        solvable = False\n",
        "        return path, solvable\n",
        "\n",
        "    def replan_path(self, cell):\n",
        "        \"\"\"\n",
        "        Function used to replan path, when encountered a block on traversing the path given by A*\n",
        "        \"\"\"\n",
        "        self.replans_count += 1  # counter to count number of restarts\n",
        "        self.blocks_encountered+=1\n",
        "        restart_cell = self.cells.get(cell)\n",
        "        restart_cell.parent = None\n",
        "        restart_cell.gval = 0\n",
        "        restart_cell.hval = self.heuristic(restart_cell.x, restart_cell.y)\n",
        "        restart_cell.fval = restart_cell.hval\n",
        "        return self.astar((restart_cell.x, restart_cell.y), self.goal)   \n",
        "\n",
        "    def execute_agent(self, start):\n",
        "        \"\"\"\n",
        "        Function that executes agent 10\n",
        "        Takes input initial random start state\n",
        "        Return the final path and cost metrics\n",
        "        \"\"\"\n",
        "        # Initializing all values\n",
        "        # print(\"Executing Agent\", self.agent)\n",
        "        start_cell = start\n",
        "        self.cells.get(start_cell).parent = None\n",
        "        goal_found = False\n",
        "        complete_path = []\n",
        "        # Find path from random start state to random goal state\n",
        "        path, solvable = self.astar(start_cell, self.goal)\n",
        "        time_step =0\n",
        "        while solvable and goal_found !=True:\n",
        "            for i,cell in enumerate(path):\n",
        "                time_step+=1\n",
        "                # sense knowledge \n",
        "                neighbors = self.get_children(cell[0],cell[1])\n",
        "                for neighbor in neighbors:\n",
        "                   x,y = neighbor\n",
        "                   if self.gridworld[x][y] == 1:\n",
        "                        self.agent_grid_view[x][y] = 1\n",
        "                 # check for goal state\n",
        "                if cell[0] == self.goal[0]  and cell[1] == self.goal[1]:\n",
        "                    complete_path.append(cell)\n",
        "                    goal_found = True\n",
        "                    break\n",
        "                else:\n",
        "                    next_cell =  path[i+1] if i+1<len(path) else None\n",
        "                    if next_cell!=None and  self.gridworld[next_cell[0]][next_cell[1]] == 1:\n",
        "                            # revert to parent and replan\n",
        "                            self.agent_grid_view[next_cell[0]][next_cell[1]] = 1\n",
        "                            path,solvable = self.replan_path(cell)\n",
        "                            break\n",
        "                    else:\n",
        "                        complete_path.append(cell)       \n",
        "        if goal_found:\n",
        "            # print('Hidden goal found')\n",
        "            return 1,len(complete_path),complete_path, self.replans_count, self.cells_processed\n",
        "        else:\n",
        "            print('target not reachable')\n",
        "            return 0,0,[],self.replans_count, self.cells_processed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Agent Implementation"
      ],
      "metadata": {
        "id": "jMpjFL2iLWBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inference function for ML agent"
      ],
      "metadata": {
        "id": "EQORxTYhEPU8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-qWBVPiJoKP"
      },
      "outputs": [],
      "source": [
        "def inference(grid, model):\n",
        "  grid = torch.tensor(grid)\n",
        "  grid = grid.float()\n",
        "  grid = grid.unsqueeze(0)\n",
        "  #grid = nn.Flatten()(grid)\n",
        "  with torch.no_grad():\n",
        "    model.eval()       \n",
        "    probabilities = model(grid)\n",
        "    probabilities = probabilities[0].to(device).detach().numpy()\n",
        "  return probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ML agent class\n"
      ],
      "metadata": {
        "id": "lz0L8ZUuEz54"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZc9SfYWJ1pK"
      },
      "outputs": [],
      "source": [
        "class Mlfinder:\n",
        "    def __init__(self, gridworld, agent_grid_view, dim, start, goal, ml_model):\n",
        "        \"\"\"\n",
        "        Builder function\n",
        "        Takes Paramets: gridworld, agent_grid_view, belief_state, dim, start, target, agent\n",
        "        \"\"\"\n",
        "        self.model = ml_model\n",
        "        self.gridworld = gridworld\n",
        "        self.dim = dim\n",
        "        self.agent_grid_view = agent_grid_view\n",
        "        self.start = start\n",
        "        self.goal = goal\n",
        "        self.cells = {}  # Initialize Cells Hash\n",
        "        self.children_hash = {}  # Initiliaze Children Hash\n",
        "        self.blocks_encountered = 0  # keep track of blocks encountered\n",
        "        self.replans_count = 0  # Counter to keep track of no of replans\n",
        "        self.cells_processed=0\n",
        "        self.examination_cost = 0  # No of nodes actually examined\n",
        "        # create cell objects\n",
        "        for i in range(0, dim):\n",
        "            for j in range(0, dim):\n",
        "                self.cells[(i, j)] = Cell(i, j)\n",
        "   \n",
        "    def get_children(self, cell_x, cell_y):\n",
        "        \"\"\"\n",
        "        function used to get the next valid reachable cells from given cell\n",
        "        Takes row,col as input and returns the next possible children of given cell\n",
        "        \"\"\"\n",
        "        if self.children_hash.get((cell_x, cell_y)) != None:\n",
        "            return self.children_hash.get((cell_x, cell_y))\n",
        "        action_offset = [\n",
        "            (1, 0),  # Right\n",
        "            (0, -1),  # Down\n",
        "            (-1, 0),  # Left\n",
        "            (0, 1),  # Up\n",
        "        ]\n",
        "        children = []\n",
        "        for n in action_offset:\n",
        "            x = cell_x + n[0]\n",
        "            y = cell_y + n[1]\n",
        "            if 0 <= x < self.dim and 0 <= y < self.dim:\n",
        "                children.append((x, y))\n",
        "        self.children_hash[(cell_x, cell_y)] = children\n",
        "        return children            \n",
        "\n",
        "    def get_cell(self, cell_x, cell_y,dir):\n",
        "        action_offset = {\n",
        "           0: (1, 0),  # Right\n",
        "            1:(0, -1),  # Down\n",
        "            2:(-1, 0),  # Left\n",
        "            3: (0, 1),  # Up\n",
        "        }\n",
        "        n = action_offset.get(dir)\n",
        "        x = cell_x + n[0]\n",
        "        y = cell_y + n[1]\n",
        "        if 0 <= x < self.dim and 0 <= y < self.dim:\n",
        "          if(self.gridworld[x][y]==1):\n",
        "            return None\n",
        "          return (x,y)\n",
        "        else:\n",
        "          return None  \n",
        "   \n",
        "    def slice_grid(self,dim,cell,agent_grid_view):\n",
        "            agent_grid_view[cell[0]][cell[1]]=5\n",
        "            padded_data = np.full((dim+10,dim+10),-1)\n",
        "            for i in range(dim):\n",
        "                 for j in range(dim):\n",
        "                    padded_data[i+4][j+4] = agent_grid_view[i][j]\n",
        "            x,y = cell\n",
        "            slice = padded_data[x-3+4:x+5+4,y-3+4:y+5+4]\n",
        "            if(slice.shape[0]<8 or slice.shape[1]<8):\n",
        "                print('ERRRORRRR',slice.shape)\n",
        "            return slice     \n",
        "    \n",
        "    def get_next_cell(self,current_cell):\n",
        "      copy_agent_view = copy.deepcopy(self.agent_grid_view)\n",
        "      local_grid = self.slice_grid(self.dim,current_cell,copy_agent_view)\n",
        "      directions = inference(local_grid, self.model)\n",
        "      return directions\n",
        "    \n",
        "    def contious_cells(self,direction,cell):\n",
        "          cell_x,cell_y =cell\n",
        "          action_offset = {\n",
        "            0: (1, 0),  # Right\n",
        "            1: (0, -1),  # Down\n",
        "            2: (-1, 0),  # Left\n",
        "            3: (0, 1),  # Up\n",
        "                           }\n",
        "          n = action_offset.get(direction)\n",
        "          prediction = []\n",
        "          for i in range(1):\n",
        "               x = cell_x + n[0]*i\n",
        "               y = cell_y + n[1]*i\n",
        "               if 0 <= x < self.dim and 0 <= y < self.dim:\n",
        "                    prediction.append((x,y))\n",
        "          return prediction \n",
        "\n",
        "    def loop_cell(self,current_cell):\n",
        "      state = True\n",
        "      directions = self.get_next_cell(current_cell)\n",
        "      cell = None\n",
        "      no_direction = 0\n",
        "      while no_direction < 4 and cell == None:\n",
        "            no_direction += 1\n",
        "            direction = np.argmax(directions)\n",
        "            directions[direction] = -1\n",
        "            cell = self.get_cell(current_cell[0],current_cell[1],direction)\n",
        "      return self.contious_cells(direction,cell)if cell!=None else []    \n",
        "\n",
        "    def execute_agent(self, start):\n",
        "        \"\"\"\n",
        "        Function that executes agent 10\n",
        "        Takes input initial random start state\n",
        "        Return the final path and cost metrics\n",
        "        \"\"\"\n",
        "        # Initializing all values\n",
        "        # print(\"Executing Agent\", self.agent)\n",
        "        start_cell = start\n",
        "        self.cells.get(start_cell).parent = None\n",
        "        goal_found = False\n",
        "        complete_path = [start]\n",
        "        # Find path from random start state to random goal state \n",
        "        path = self.loop_cell(start)\n",
        "\n",
        "        time_step =0\n",
        "        while  goal_found !=True and len(path)>0 and time_step<500:\n",
        "            for i,cell in enumerate(path):\n",
        "                time_step+=1\n",
        "\n",
        "                if self.gridworld[cell[0]][cell[1]]==0:\n",
        "                  # sense knowledge \n",
        "                   neighbors = self.get_children(cell[0],cell[1])\n",
        "                   for neighbor in neighbors:\n",
        "                     x,y = neighbor\n",
        "                     if self.gridworld[x][y] == 1:\n",
        "                          self.agent_grid_view[x][y] = 1\n",
        "                 # check for goal state\n",
        "                if cell[0] == self.goal[0]  and cell[1] == self.goal[1]:\n",
        "                    complete_path.append(cell)\n",
        "                    goal_found = True\n",
        "                    break\n",
        "                else:\n",
        "                    if self.gridworld[cell[0]][cell[1]] == 1:\n",
        "                            # revert to parent and replan\n",
        "                            self.agent_grid_view[cell[0]][cell[1]] = 1\n",
        "                            prev = complete_path.pop()\n",
        "                            path= self.loop_cell(prev)\n",
        "                            break\n",
        "                    else:\n",
        "                        complete_path.append(cell)\n",
        "                        path=self.loop_cell(cell) \n",
        "                        \n",
        "        if goal_found:\n",
        "            print('goal found by ML')\n",
        "            return 1,len(complete_path),complete_path, self.replans_count, self.cells_processed\n",
        "        else:\n",
        "            print('target not reachable')\n",
        "            return 0,0,[],self.replans_count, self.cells_processed"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execute both agents"
      ],
      "metadata": {
        "id": "BAV4BhenFFYX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {
        "id": "9xU7hYPoHQjQ"
      },
      "outputs": [],
      "source": [
        "from time import process_time\n",
        "\n",
        "def test_ml_agent(number_of_mazes):\n",
        "  dim = 50\n",
        "  start =(0,0)\n",
        "  goal =(dim-1,dim-1)\n",
        "\n",
        "  '''[[agent_solved, agent_unsolved],\n",
        "    [ml_agent_solved, ml_agent_unsolved]]'''\n",
        "  confusion_matrix = np.array([[0, 0], \n",
        "                        [0, 0]])\n",
        "  total_path_length = 0\n",
        "  total_run_time = 0\n",
        "  total_ml_path_length = 0\n",
        "  total_ml_run_time = 0\n",
        "\n",
        "  solved_agent =0\n",
        "  solved_ml_agent =0\n",
        "  for i in range(number_of_mazes):\n",
        "    print(i,'sample------------------')\n",
        "    gridworld= generate_gridworld(dim, 0.3)\n",
        "\n",
        "    # start = process_time()\n",
        "    goal_found_agent,path_length,_, _, _ = PathFinder(gridworld, np.zeros((dim, dim)), dim, start, goal).execute_agent(start)\n",
        "\n",
        "    solved_agent+=goal_found_agent \n",
        "    # runtime = process_time() - start\n",
        "\n",
        "    ml_model = ConvulationalNeuralNet()\n",
        "    PATH='model/proj1/cnn.pt' \n",
        "    ml_model.load_state_dict(torch.load(PATH))\n",
        "    # start_ml = process_time()\n",
        "    goal_found_ml, ml_path_length,_, _, _ = Mlfinder(gridworld, np.zeros((dim, dim)), dim, start, goal, ml_model).execute_agent(start)\n",
        "    # ml_runtime = process_time() - start_ml\n",
        "    solved_ml_agent+=goal_found_ml\n",
        "    \n",
        "    total_path_length += path_length\n",
        "    total_ml_path_length += ml_path_length\n",
        "    # total_run_time += runtime\n",
        "    # total_ml_run_time += ml_runtime\n",
        "    if goal_found_agent and goal_found_ml:\n",
        "      confusion_matrix[0][0] += 1\n",
        "    elif not goal_found_agent and not goal_found_ml:\n",
        "      confusion_matrix[1][1] += 1\n",
        "    elif not goal_found_agent and goal_found_ml:\n",
        "      confusion_matrix[1][0] += 1\n",
        "    elif goal_found_agent and not goal_found_ml:\n",
        "      confusion_matrix[0][1] += 1\n",
        "    else:\n",
        "      print(\"NOOB\")\n",
        "    print(i,'sample------------------')\n",
        "  accuracy = (confusion_matrix[0][0] + confusion_matrix[1][1]) / confusion_matrix.sum()\n",
        "  recall = confusion_matrix[0][0]/(confusion_matrix[0][0] + confusion_matrix[0][1])\n",
        "  precision = confusion_matrix[0][0]/(confusion_matrix[0][0] + confusion_matrix[1][0])\n",
        "  \n",
        "  print('avg normal ', total_path_length/solved_agent)\n",
        "  print('avg ml ', total_ml_path_length/solved_ml_agent)\n",
        "  return confusion_matrix, accuracy, precision, recall, total_path_length/solved_agent, total_ml_path_length/solved_ml_agent\n",
        "#traj len, planning time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def write_to_file(states, file_name):\n",
        "       try:\n",
        "          print('number of states apend',len(states))\n",
        "          joblib.dump(states, file_name, compress=3)\n",
        "       except OverflowError:  \n",
        "            print (\"OverFlow Exception Raised.\")"
      ],
      "metadata": {
        "id": "XcMYCRF5sYex"
      },
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_tests = 30\n",
        "sum_confusion_matrix = np.array([[0, 0], \n",
        "                            [0, 0]])\n",
        "sum_accuracy, sum_precision, sum_recall, sum_path_length, sum_ml_path_length = 0, 0, 0, 0, 0\n",
        "graph_data = []\n",
        "for i in range(number_of_tests):\n",
        "  print('test no', i)\n",
        "  confusion_matrix, accuracy, precision, recall, path_length, ml_path_length = test_ml_agent(number_of_mazes=100)\n",
        "  graph_data.append([i, confusion_matrix, accuracy, precision, recall, path_length, ml_path_length])\n",
        "  # sum_confusion_matrix += confusion_matrix\n",
        "  # sum_accuracy += accuracy\n",
        "  # sum_precision += precision\n",
        "  # sum_recall += recall\n",
        "  # sum_path_length += path_length\n",
        "  # sum_ml_path_length += ml_path_length\n",
        "\n",
        "\n",
        "\n",
        "# avg_confusion_matrix = sum_confusion_matrix / number_of_tests\n",
        "# avg_accuracy = sum_accuracy / number_of_tests\n",
        "# avg_precision = sum_precision / number_of_tests\n",
        "# avg_recall = sum_recall / number_of_tests\n",
        "# avg_path_length = sum_path_length / number_of_tests\n",
        "# avg_ml_path_length = sum_ml_path_length / number_of_tests\n",
        "# print('avg')\n",
        "# print(avg_confusion_matrix, avg_accuracy, avg_precision, avg_recall)"
      ],
      "metadata": {
        "id": "jwu-AGMfFNfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = 'proj1_cnn_data'\n",
        "write_to_file(graph_data, file_name)\n"
      ],
      "metadata": {
        "id": "9iSQyKKi8ljd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = joblib.load('proj1_cnn_data')\n",
        "print(len(data))"
      ],
      "metadata": {
        "id": "stILqJP-tisc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jXZXXq0h3kP8",
        "iL-xuTxYG0g8",
        "rbNlQN_w0jfj",
        "aTHSUq_LRHrS",
        "7wDbJrnEcuXD",
        "iBwNWHOj-7tc",
        "jMpjFL2iLWBR"
      ],
      "name": "AI_Project-4-Part1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}